{"cells":[{"cell_type":"markdown","metadata":{},"source":["https://arxiv.org/abs/1512.03385  \n","https://arxiv.org/abs/1812.01187  \n","https://arxiv.org/abs/1706.02677  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# conclusion? \n","# LayerNorm is better than batchNorm. (it came out as an improvement) \n","# but, LayerNorm depends on the Emb size, whereas BatchNorm on BS, therefore its easy to implement a dynamic (image size independent) convlayers using batchnorm than layernorm\n","# https://arxiv.org/abs/1706.02677 init gamma of Normlayer just before the residual connection with 0 helps in learning, why think about it. Hint \"residual\"\n","# https://arxiv.org/abs/1812.01187 stem in the beginning and AvgPool replaces FC, helps to reduce computation and parameters respectively\n","# 1x1 convs used in bottleneck layers are faster than original residual block, on addition to increasing depth"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:07:54.255159Z","iopub.status.busy":"2024-05-28T15:07:54.254719Z","iopub.status.idle":"2024-05-28T15:07:54.267796Z","shell.execute_reply":"2024-05-28T15:07:54.266787Z","shell.execute_reply.started":"2024-05-28T15:07:54.255105Z"},"trusted":true},"outputs":[],"source":["import numpy\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:07:54.329815Z","iopub.status.busy":"2024-05-28T15:07:54.329496Z","iopub.status.idle":"2024-05-28T15:07:57.732729Z","shell.execute_reply":"2024-05-28T15:07:57.731961Z","shell.execute_reply.started":"2024-05-28T15:07:54.329790Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:07:57.734604Z","iopub.status.busy":"2024-05-28T15:07:57.734247Z","iopub.status.idle":"2024-05-28T15:08:04.783333Z","shell.execute_reply":"2024-05-28T15:08:04.782029Z","shell.execute_reply.started":"2024-05-28T15:07:57.734580Z"},"trusted":true},"outputs":[],"source":["from fastai.vision.all import *"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:04.786617Z","iopub.status.busy":"2024-05-28T15:08:04.786204Z","iopub.status.idle":"2024-05-28T15:08:04.800064Z","shell.execute_reply":"2024-05-28T15:08:04.798198Z","shell.execute_reply.started":"2024-05-28T15:08:04.786581Z"},"trusted":true},"outputs":[],"source":["# ConvLayer: Conv-Norm-Act\n","class ConvLayer(nn.Module):\n","    def __init__(self, ci, co, k=3, s=1, p=None, norm=True, norm_init_zero=False, act=True):\n","        super().__init__()\n","        if p is None: p = k//2\n","        self.conv = nn.Conv2d(ci, co, kernel_size=k, stride=s, padding=p)\n","        if norm:\n","            self.norm = nn.BatchNorm2d(co)\n","            if norm_init_zero:\n","                self.norm.weight.data.fill_(0)\n","                if self.norm.bias is not None:\n","                    self.norm.bias.data.fill_(0)\n","        else:\n","            self.norm = None\n","        self.act = nn.GELU() if act else None\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        if self.norm is not None:\n","            x = self.norm(x)\n","        if self.act is not None:\n","            x = self.act(x)\n","        return x\n","\n","# ConvLayer(3, 32)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:04.803758Z","iopub.status.busy":"2024-05-28T15:08:04.802916Z","iopub.status.idle":"2024-05-28T15:08:04.818486Z","shell.execute_reply":"2024-05-28T15:08:04.817470Z","shell.execute_reply.started":"2024-05-28T15:08:04.803635Z"},"trusted":true},"outputs":[],"source":["# https://arxiv.org/pdf/1812.01187\n","def _stem(*sizes):\n","    net = []\n","    for i in range(len(sizes)-1):\n","        net.append(ConvLayer(sizes[i], sizes[i+1], 3, s=2 if i==0 else 1))\n","    return nn.Sequential(*net, nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n","\n","# _stem(3,32,32,64)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:04.820422Z","iopub.status.busy":"2024-05-28T15:08:04.820011Z","iopub.status.idle":"2024-05-28T15:08:04.829884Z","shell.execute_reply":"2024-05-28T15:08:04.828910Z","shell.execute_reply.started":"2024-05-28T15:08:04.820390Z"},"trusted":true},"outputs":[],"source":["def _conv_block(ci, co, s=1, bottleneck=False):\n","    if bottleneck:\n","        layers = [\n","            ConvLayer(ci, co, k=1, s=s, p=0),\n","            ConvLayer(co, co, s=s),\n","            ConvLayer(co, co, k=1, s=s, p=0, norm_init_zero=True, act=False),\n","        ]\n","    else:\n","        layers = [\n","            ConvLayer(ci, co, s=s),\n","            ConvLayer(co, co, s=s, norm_init_zero=True, act=False),\n","        ]\n","    return nn.Sequential(*layers)\n","\n","# _conv_block(64, 64)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:04.831692Z","iopub.status.busy":"2024-05-28T15:08:04.831324Z","iopub.status.idle":"2024-05-28T15:08:04.842345Z","shell.execute_reply":"2024-05-28T15:08:04.841346Z","shell.execute_reply.started":"2024-05-28T15:08:04.831659Z"},"trusted":true},"outputs":[],"source":["# residual block\n","class noop(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","    def forward(self, x):\n","        return x\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, ci, co, s=1, bottle_neck=False):\n","        super().__init__()\n","        self.convs = _conv_block(ci, co, s=s, bottleneck=bottle_neck)\n","        self.idconv = noop() if ci==co else ConvLayer(ci, co, k=1, p=0, act=False) #residual\n","        self.pool = noop() if s==1 else nn.AvgPool2d(2, ceil_mode=True)\n","    def forward(self, x):\n","        out = self.convs(x)\n","        residual = self.idconv(self.pool(x))\n","#         if out.shape != residual.shape:\n","#             residual = self.pool(residual)\n","        return F.gelu(out + residual)\n","\n","# ResBlock(30,64,128)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:04.843822Z","iopub.status.busy":"2024-05-28T15:08:04.843519Z","iopub.status.idle":"2024-05-28T15:08:06.784267Z","shell.execute_reply":"2024-05-28T15:08:06.783271Z","shell.execute_reply.started":"2024-05-28T15:08:04.843797Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 3, 128, 128])\n","torch.Size([128, 64, 32, 32])\n","torch.Size([128, 128, 32, 32])\n"]}],"source":["# checking above implementation--\n","# starting img, bs 128\n","x = torch.randn((128, 3, 128, 128))\n","print(x.shape)\n","x = _stem(3,32,32,64)(x)\n","print(x.shape) # stem out\n","x = ResBlock(64, 128)(x) # residual block (bottleneck)\n","print(x.shape)\n","# # now create a loop"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:06.785720Z","iopub.status.busy":"2024-05-28T15:08:06.785437Z","iopub.status.idle":"2024-05-28T15:08:16.799201Z","shell.execute_reply":"2024-05-28T15:08:16.798295Z","shell.execute_reply.started":"2024-05-28T15:08:06.785696Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([128, 1000])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# stem + [2,2,2,2] blocks\n","# 3c + 1p +  4 * 2 * 2c\n","# 3c + 16c\n","# 19 conv == resnet18\n","\n","# input goes through stem\n","# if starting residual block, stride 1 else stride 2\n","# progressive depth of residual blocks\n","    # 64 -> 64 -> 128 -> 256 -> 512\n","\n","# resnet\n","class ResNet(nn.Module):\n","    def __init__(self, layers, n_out, bottle_neck=False):\n","        super().__init__()\n","        self.stem = _stem(3,32,32,64)\n","        block_sz = [64,64,128,256,512]\n","        blocks = []\n","        for i in range(len(block_sz)-1):\n","            stride = 1 # if i==0 else 2 # but it sucks, to much compression, we already have Avgpool\n","            blocks.append(self._make_layer(block_sz[i], block_sz[i+1], layers[i], stride, bottle_neck))\n","        self.core = nn.Sequential(*blocks)\n","        ## below could be in Sequential as well, but nvm\n","        self.final_pool = nn.AdaptiveAvgPool2d(1)\n","        self.flat = nn.Flatten()\n","        self.fc = nn.Linear(block_sz[-1], n_out)\n","        \n","    def _make_layer(self, _in, _out, blocks, stride, bottle_neck=False):\n","        net = []\n","        for _ in range(1, blocks):\n","            net.append(ResBlock(_in,_out,s=stride, bottle_neck=bottle_neck))\n","        return nn.Sequential(*net)\n","\n","    def forward(self, x):\n","#         import time\n","#         st = time.monotonic()\n","        x = self.stem(x)\n","        x = self.core(x)\n","        x = self.final_pool(x)\n","        x = self.flat(x)\n","        x = self.fc(x)\n","#         et = time.monotonic()\n","#         print((et-st)//1) # 13 sec single forward pass, bleh\n","        return x\n","\n","x = torch.randn((128, 3, 128, 128))\n","resnet = ResNet([2,2,2,2], 1000)\n","resnet(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# ResNet\n","- Init BN's gamma with 0's if the layer is just before the \"+\" (residual addition)\n","\n","- stem\n","    - instead of directly starting with resblock, we start with few convs\n","    - reason: resblocks are computational expensive, initially when the image is original, it requires more computation\n","- 4 group of resnet blocks\n","    - filters size for each blocks are: 64, 128, 256, 512\n","    - except 1st (just after MaxPool layer), each has stride = 2\n","\n","\n","# ResNet-18, -34, -50 etc. what are these?\n","- the architecture contains 18 conv layers\n","\n","\n","1. get imagenette dataset from fastai\n","2. get things done  \n","    2.1 dataaugmentation-- mixup  \n","3. implement resnet-50 (i think good enough to fit in memory)\n","4. Train model  \n","    4.1 raw  \n","    4.2 label smoothing  1. get imagenette dataset from fastai\n","2. get things done  \n","    2.1 dataaugmentation-- mixup  \n","3. implement resnet-50 (i think good enough to fit in memory)\n","4. Train model  \n","    4.1 raw  \n","    4.2 label smoothing  "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:16.800493Z","iopub.status.busy":"2024-05-28T15:08:16.800204Z","iopub.status.idle":"2024-05-28T15:08:16.804877Z","shell.execute_reply":"2024-05-28T15:08:16.803991Z","shell.execute_reply.started":"2024-05-28T15:08:16.800469Z"},"trusted":true},"outputs":[],"source":["from fastai.vision.all import URLs"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:16.807629Z","iopub.status.busy":"2024-05-28T15:08:16.807362Z","iopub.status.idle":"2024-05-28T15:08:57.239336Z","shell.execute_reply":"2024-05-28T15:08:57.238344Z","shell.execute_reply.started":"2024-05-28T15:08:16.807607Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      <progress value='341663744' class='' max='341663724' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [341663744/341663724 00:32&lt;00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["/root/.fastai/data/imagenette2-320\n"]}],"source":["def get_data(url, presize, resize):\n","    path = untar_data(url)\n","    print(path)\n","    return DataBlock(\n","        blocks=(ImageBlock, CategoryBlock), get_items=get_image_files,\n","        splitter=GrandparentSplitter(valid_name='val'),\n","        get_y=parent_label, item_tfms=Resize(presize),\n","        batch_tfms=[*aug_transforms(min_scale=0.5, size=resize),\n","        Normalize.from_stats(*imagenet_stats)],\n","    ).dataloaders(path, bs=64)\n","dls = get_data(URLs.IMAGENETTE_320, presize=320, resize=224)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:57.240861Z","iopub.status.busy":"2024-05-28T15:08:57.240569Z","iopub.status.idle":"2024-05-28T15:08:57.245403Z","shell.execute_reply":"2024-05-28T15:08:57.244329Z","shell.execute_reply.started":"2024-05-28T15:08:57.240835Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:57.247403Z","iopub.status.busy":"2024-05-28T15:08:57.247012Z","iopub.status.idle":"2024-05-28T15:08:57.268514Z","shell.execute_reply":"2024-05-28T15:08:57.267599Z","shell.execute_reply.started":"2024-05-28T15:08:57.247372Z"},"trusted":true},"outputs":[],"source":["train,valid = dls.train, dls.valid"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:10:36.790742Z","iopub.status.busy":"2024-05-28T15:10:36.789936Z","iopub.status.idle":"2024-05-28T15:39:51.172008Z","shell.execute_reply":"2024-05-28T15:39:51.170890Z","shell.execute_reply.started":"2024-05-28T15:10:36.790707Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 2.0636 Acc: 0.2871\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.9042 Acc: 0.3666\n","Epoch 1/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.8198 Acc: 0.3877\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.7808 Acc: 0.4120\n","Epoch 2/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.7112 Acc: 0.4273\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.6898 Acc: 0.4548\n","Epoch 3/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.6185 Acc: 0.4636\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.6109 Acc: 0.4874\n","Epoch 4/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.5412 Acc: 0.4963\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.5624 Acc: 0.5085\n","Epoch 5/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.4691 Acc: 0.5168\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.4333 Acc: 0.5615\n","Epoch 6/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.4168 Acc: 0.5442\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.3961 Acc: 0.5671\n","Epoch 7/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.3694 Acc: 0.5595\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.3622 Acc: 0.5781\n","Epoch 8/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.3349 Acc: 0.5669\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.3260 Acc: 0.5819\n","Epoch 9/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.3015 Acc: 0.5745\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.2955 Acc: 0.5969\n","Epoch 10/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.2682 Acc: 0.5888\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.2743 Acc: 0.6079\n","Epoch 11/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.2419 Acc: 0.5966\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.2932 Acc: 0.6041\n","Epoch 12/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.2137 Acc: 0.6106\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.3055 Acc: 0.5893\n","Epoch 13/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.1981 Acc: 0.6100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.2926 Acc: 0.6008\n","Epoch 14/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.1678 Acc: 0.6267\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.2646 Acc: 0.6000\n","Epoch 15/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.1547 Acc: 0.6266\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.3014 Acc: 0.5939\n","Epoch 16/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.1335 Acc: 0.6347\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.2180 Acc: 0.6166\n","Epoch 17/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.1202 Acc: 0.6379\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.1789 Acc: 0.6316\n","Epoch 18/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.0954 Acc: 0.6477\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.2575 Acc: 0.6171\n","Epoch 19/19\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [01:13<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.0783 Acc: 0.6574\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 62/62 [00:14<00:00,  4.32it/s]"]},{"name":"stdout","output_type":"stream","text":["valid Loss: 1.1130 Acc: 0.6596\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import tqdm\n","\n","def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, device='cuda'):\n","    model.to(device)\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        for phase in ['train', 'valid']:\n","            if phase == 'train': model.train()\n","            else: model.eval()\n","            lossi = 0.0\n","            acci = 0\n","\n","            for inp,targs in tqdm.tqdm(dataloaders[phase]):\n","                inputs = torch.tensor(inp.cpu().numpy()).to(device)\n","                labels = torch.tensor(targs.cpu().numpy()).to(device)\n","                model.zero_grad()\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    out = model(inputs)\n","                    preds = torch.argmax(out.softmax(1), 1)\n","                    loss = criterion(out, labels)\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                lossi += loss.item() * inputs.size(0)\n","                acci  += torch.sum(preds == labels.data)\n","            \n","            epoch_loss = lossi / len(dataloaders[phase].dataset)\n","            epoch_acc = acci.double() / len(dataloaders[phase].dataset)\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","    return model\n","\n","\n","model = ResNet([2, 2, 2, 2], n_out=10) #resnet18\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","dataloaders = {'train': dls.train, 'valid': dls.valid}\n","\n","model = train_model(model, dataloaders, criterion, optimizer, num_epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
